{
    "id": "1503933356",
    "title": "Deep multimodal learning for Audio-Visual Speech Recognition",
    "venue": "international conference on acoustics, speech, and signal processing",
    "year": 2015,
    "authors": [
        {
            "name": "Youssef Mroueh",
            "id": "2511455707",
            "org": "Poggio Lab, CSAIL, MIT, USA"
        },
        {
            "name": "Etienne Marcheret",
            "id": "2055496345",
            "org": "IBM T.J Watson Research Center, USA"
        },
        {
            "name": "Vaibhava Goel",
            "id": "2136818396",
            "org": "IBM T.J Watson Research Center, USA"
        }
    ],
    "fields_of_study": [
        "Word error rate",
        "Speech coding",
        "Artificial intelligence",
        "Multimodal learning",
        "Audio-visual speech recognition",
        "Pattern recognition",
        "Acoustic model",
        "Computer science",
        "Audio mining",
        "Voice activity detection",
        "Speech recognition",
        "Speech processing",
        "Natural language processing"
    ],
    "references": [
        "154472438",
        "1211870555",
        "1523385540",
        "1531976713",
        "1964822888",
        "2072072671",
        "2100235303",
        "2124397839",
        "2127426251",
        "2135217348",
        "2142075667",
        "2153606381",
        "2164587673",
        "2171209807",
        "2184188583"
    ]
}